{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO2ch1DwvoK6bDH4Dv4MDu3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asheta66/Machine-Learning-2024/blob/main/ELM/FFNN_ELM_Classification_Updated.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCTUrJoR1v8m"
      },
      "outputs": [],
      "source": [
        "# diabetes_ffnn_elm_fixed.py\n",
        "# ------------------------------------------------------------\n",
        "# Binary classification for Diabetes/Heart dataset with:\n",
        "#   - Feedforward Neural Network (FFNN, sklearn MLPClassifier in a Pipeline)\n",
        "#   - Extreme Learning Machine (ELM)\n",
        "#   - Proper ROC/Confusion plots saved to ./figs\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n",
        "    confusion_matrix, RocCurveDisplay\n",
        ")\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "# ----------------------------\n",
        "# Repro & I/O\n",
        "# ----------------------------\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)\n",
        "os.makedirs(\"figs\", exist_ok=True)\n",
        "\n",
        "# ============================================================\n",
        "# 1) Load data\n",
        "# ============================================================\n",
        "CSV_PATH = \"diabetes.csv\"   # or \"heart.csv\"\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "df.columns = [c.strip() for c in df.columns]\n",
        "\n",
        "# Auto-detect target column\n",
        "if \"Outcome\" in df.columns:\n",
        "    target = \"Outcome\"\n",
        "else:\n",
        "    raise ValueError(\"Target column 'Outcome' not found in the dataset.\")\n",
        "\n",
        "feature_cols = [c for c in df.columns if c != target]\n",
        "X = df[feature_cols].copy()\n",
        "y = df[target].astype(int).copy()\n",
        "\n",
        "numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
        "categorical_cols = [c for c in X.columns if c not in numeric_cols]\n",
        "\n",
        "# ============================================================\n",
        "# 2) Preprocessing\n",
        "# ============================================================\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"scaler\", StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
        "])\n",
        "\n",
        "preprocess = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", numeric_transformer, numeric_cols),\n",
        "        (\"cat\", categorical_transformer, categorical_cols)\n",
        "    ],\n",
        "    remainder=\"drop\"\n",
        ")\n",
        "\n",
        "# ============================================================\n",
        "# 3) ELM Classifier\n",
        "# ============================================================\n",
        "class ELMClassifier(BaseEstimator, ClassifierMixin):\n",
        "    \"\"\"\n",
        "    Extreme Learning Machine (binary classification)\n",
        "      - Random input → hidden weights\n",
        "      - Supports multiple activations\n",
        "      - Output weights via ridge regression\n",
        "    \"\"\"\n",
        "    def __init__(self, n_hidden=500, activation=\"relu\", alpha=1e-2, random_state=RANDOM_STATE):\n",
        "        self.n_hidden = n_hidden\n",
        "        self.activation = activation\n",
        "        self.alpha = alpha\n",
        "        self.random_state = random_state\n",
        "\n",
        "    def _act(self, Z):\n",
        "        if self.activation == \"relu\":\n",
        "            return np.maximum(0.0, Z)\n",
        "        elif self.activation == \"sigmoid\":\n",
        "            return 1.0 / (1.0 + np.exp(-Z))\n",
        "        elif self.activation == \"tanh\":\n",
        "            return np.tanh(Z)\n",
        "        elif self.activation == \"linear\":\n",
        "            return Z\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown activation: {self.activation}\")\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        rng = np.random.default_rng(self.random_state)\n",
        "        X = np.asarray(X)\n",
        "        y = np.asarray(y).astype(float).reshape(-1, 1)\n",
        "        n_features = X.shape[1]\n",
        "\n",
        "        # Random projection\n",
        "        self.W_ = rng.normal(loc=0.0, scale=1.0, size=(n_features, self.n_hidden))\n",
        "        self.b_ = rng.normal(loc=0.0, scale=1.0, size=(self.n_hidden,))\n",
        "        H = self._act(X @ self.W_ + self.b_)\n",
        "\n",
        "        # Ridge regression on hidden outputs\n",
        "        self.ridge_ = Ridge(alpha=self.alpha, fit_intercept=False, random_state=self.random_state)\n",
        "        self.ridge_.fit(H, y)\n",
        "        return self\n",
        "\n",
        "    def decision_function(self, X):\n",
        "        X = np.asarray(X)\n",
        "        H = self._act(X @ self.W_ + self.b_)\n",
        "        return self.ridge_.predict(H).ravel()\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        scores = self.decision_function(X)\n",
        "        probs1 = 1.0 / (1.0 + np.exp(-np.clip(scores, -20, 20)))\n",
        "        probs0 = 1.0 - probs1\n",
        "        return np.vstack([probs0, probs1]).T\n",
        "\n",
        "    def predict(self, X):\n",
        "        return (self.predict_proba(X)[:, 1] >= 0.5).astype(int)\n",
        "\n",
        "# ============================================================\n",
        "# 4) Metrics Helper\n",
        "# ============================================================\n",
        "def compute_metrics(model_name, y_true, y_proba, y_pred):\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
        "    rec = recall_score(y_true, y_pred)  # sensitivity\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    auc = roc_auc_score(y_true, y_proba[:, 1])\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "    spec = tn / (tn + fp) if (tn + fp) > 0 else float(\"nan\")\n",
        "    return {\n",
        "        \"model\": model_name, \"accuracy\": acc, \"precision\": prec,\n",
        "        \"recall\": rec, \"specificity\": spec, \"f1\": f1, \"roc_auc\": auc\n",
        "    }\n",
        "\n",
        "# ============================================================\n",
        "# 5) Train/Test Split\n",
        "# ============================================================\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "# Pre-fit a transformer for ELM (we’ll reuse same preprocessing)\n",
        "preprocess_fit = preprocess.fit(X_train, y_train)\n",
        "Xtr_enc = preprocess_fit.transform(X_train)\n",
        "Xte_enc = preprocess_fit.transform(X_test)\n",
        "\n",
        "# ============================================================\n",
        "# 6) Define Models\n",
        "# ============================================================\n",
        "ffnn = Pipeline(steps=[\n",
        "    (\"preprocess\", preprocess),\n",
        "    (\"clf\", MLPClassifier(\n",
        "        hidden_layer_sizes=(64, 32),\n",
        "        activation=\"relu\",\n",
        "        solver=\"adam\",\n",
        "        alpha=1e-3,\n",
        "        max_iter=500,\n",
        "        random_state=RANDOM_STATE,\n",
        "        early_stopping=True,\n",
        "        n_iter_no_change=15,\n",
        "        validation_fraction=0.15,\n",
        "        verbose=False\n",
        "    ))\n",
        "])\n",
        "\n",
        "elm_configs = [\n",
        "    {\"n_hidden\": 256,  \"activation\": \"relu\",    \"alpha\": 1e-2},\n",
        "    {\"n_hidden\": 500,  \"activation\": \"sigmoid\", \"alpha\": 1e-2},\n",
        "    {\"n_hidden\": 1000, \"activation\": \"tanh\",    \"alpha\": 1e-3},\n",
        "    {\"n_hidden\": 2000, \"activation\": \"relu\",    \"alpha\": 1e-1},\n",
        "]\n",
        "\n",
        "# ============================================================\n",
        "# 7) Train and Evaluate\n",
        "# ============================================================\n",
        "results = []\n",
        "\n",
        "# ---- FFNN (Pipeline) ----\n",
        "ffnn.fit(X_train, y_train)\n",
        "ytr_ffnn_proba = ffnn.predict_proba(X_train)\n",
        "yte_ffnn_proba = ffnn.predict_proba(X_test)\n",
        "ytr_ffnn_pred  = ffnn.predict(X_train)\n",
        "yte_ffnn_pred  = ffnn.predict(X_test)\n",
        "results.append(compute_metrics(\"FFNN\", y_test, yte_ffnn_proba, yte_ffnn_pred))\n",
        "\n",
        "# ---- ELM: train multiple configs, keep BEST by test ROC AUC ----\n",
        "best_elm = None\n",
        "best_auc = -np.inf\n",
        "best_name = None\n",
        "\n",
        "for cfg in elm_configs:\n",
        "    elm = ELMClassifier(**cfg, random_state=RANDOM_STATE)\n",
        "    elm.fit(Xtr_enc, y_train)\n",
        "\n",
        "    # train & test probabilities/preds\n",
        "    ytr_elm_proba = elm.predict_proba(Xtr_enc)\n",
        "    yte_elm_proba = elm.predict_proba(Xte_enc)\n",
        "    ytr_elm_pred  = elm.predict(Xtr_enc)\n",
        "    yte_elm_pred  = elm.predict(Xte_enc)\n",
        "\n",
        "    name = f\"ELM (h={cfg['n_hidden']}, act={cfg['activation']}, α={cfg['alpha']})\"\n",
        "    mt = compute_metrics(name, y_test, yte_elm_proba, yte_elm_pred)\n",
        "    results.append(mt)\n",
        "\n",
        "    if mt[\"roc_auc\"] > best_auc:\n",
        "        best_auc   = mt[\"roc_auc\"]\n",
        "        best_elm   = elm\n",
        "        best_name  = name\n",
        "        best_ytr_proba = ytr_elm_proba\n",
        "        best_yte_proba = yte_elm_proba\n",
        "        best_ytr_pred  = ytr_elm_pred\n",
        "        best_yte_pred  = yte_elm_pred\n",
        "\n",
        "print(\"Best ELM:\", best_name, \"| Test ROC AUC:\", round(best_auc, 4))\n",
        "\n",
        "# ============================================================\n",
        "# 8) Plots (Confusions + Combined ROC)\n",
        "# ============================================================\n",
        "def plot_confusions(y_train, y_train_pred, y_test, y_test_pred, model_name, class_names=None):\n",
        "    \"\"\"Draw and save train/test confusion matrices for a model.\"\"\"\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "    for ax, (y_true, y_pred, title) in zip(\n",
        "        axes,\n",
        "        [(y_train, y_train_pred, \"Train\"), (y_test, y_test_pred, \"Test\")]\n",
        "    ):\n",
        "        cm = confusion_matrix(y_true, y_pred)\n",
        "        ax.imshow(cm, cmap=plt.cm.Blues, interpolation='nearest')\n",
        "        ax.set_title(f\"{model_name} - {title}\")\n",
        "        ax.set_xlabel(\"Predicted\")\n",
        "        ax.set_ylabel(\"True\")\n",
        "\n",
        "        n_classes = cm.shape[0]\n",
        "        ax.set_xticks(np.arange(n_classes))\n",
        "        ax.set_yticks(np.arange(n_classes))\n",
        "        if class_names is None:\n",
        "            ax.set_xticklabels([f\"{i}\" for i in range(n_classes)], rotation=45, ha=\"right\")\n",
        "            ax.set_yticklabels([f\"{i}\" for i in range(n_classes)])\n",
        "        else:\n",
        "            ax.set_xticklabels(class_names, rotation=45, ha=\"right\")\n",
        "            ax.set_yticklabels(class_names)\n",
        "\n",
        "        for i in range(cm.shape[0]):\n",
        "            for j in range(cm.shape[1]):\n",
        "                ax.text(j, i, str(cm[i, j]), ha='center', va='center',\n",
        "                        color='green', fontsize=12, fontweight='bold')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    out = f\"figs/confusion_{model_name.lower().replace(' ', '_')}.png\"\n",
        "    plt.savefig(out, dpi=150)\n",
        "    plt.close(fig)\n",
        "    print(f\"Saved confusion matrix figure for {model_name} -> {out}\")\n",
        "\n",
        "def plot_combined_rocs(\n",
        "    y_train_ffnn, y_train_proba_ffnn, y_test_ffnn, y_test_proba_ffnn,\n",
        "    y_train_elm,  y_train_proba_elm,  y_test_elm,  y_test_proba_elm\n",
        "):\n",
        "    \"\"\"Draw FFNN and ELM ROC curves (Train & Test) side by side (binary).\"\"\"\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "    # FFNN\n",
        "    RocCurveDisplay.from_predictions(y_train_ffnn, y_train_proba_ffnn[:, 1],\n",
        "                                     name=\"FFNN Train\", ax=axes[0])\n",
        "    RocCurveDisplay.from_predictions(y_test_ffnn,  y_test_proba_ffnn[:, 1],\n",
        "                                     name=\"FFNN Test\",  ax=axes[0])\n",
        "    axes[0].set_title(\"FFNN ROC (Train & Test)\", fontsize=12)\n",
        "    axes[0].legend(fontsize=10)\n",
        "\n",
        "    # ELM\n",
        "    RocCurveDisplay.from_predictions(y_train_elm, y_train_proba_elm[:, 1],\n",
        "                                     name=\"ELM Train\", ax=axes[1])\n",
        "    RocCurveDisplay.from_predictions(y_test_elm,  y_test_proba_elm[:, 1],\n",
        "                                     name=\"ELM Test\",  ax=axes[1])\n",
        "    axes[1].set_title(\"ELM ROC (Train & Test)\", fontsize=12)\n",
        "    axes[1].legend(fontsize=10)\n",
        "\n",
        "    fig.suptitle(\"ROC Curves — FFNN vs Best ELM\", fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    out = \"figs/roc_ffnn_bestelm_comparison.png\"\n",
        "    plt.savefig(out, dpi=150)\n",
        "    plt.close(fig)\n",
        "    print(f\"Saved combined ROC figure -> {out}\")\n",
        "\n",
        "# — Confusions —\n",
        "plot_confusions(y_train, ytr_ffnn_pred, y_test, yte_ffnn_pred, model_name=\"FFNN\")\n",
        "plot_confusions(y_train, best_ytr_pred,  y_test, best_yte_pred,  model_name=\"Best_ELM\")\n",
        "\n",
        "# — Combined ROC —\n",
        "plot_combined_rocs(\n",
        "    y_train, ytr_ffnn_proba, y_test, yte_ffnn_proba,\n",
        "    y_train, best_ytr_proba,  y_test, best_yte_proba\n",
        ")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 9) Results Table\n",
        "# ============================================================\n",
        "res_df = pd.DataFrame(results).sort_values(by=\"roc_auc\", ascending=False)\n",
        "print(\"\\nModel scoreboard (sorted by Test ROC AUC):\")\n",
        "print(res_df.to_string(index=False))\n",
        "res_df.to_csv(\"figs/results_ffnn_elm.csv\", index=False)\n",
        "print(\"Saved CSV -> figs/results_ffnn_elm.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tf79sVlq6fTK",
        "outputId": "40717762-ddfd-4236-bf36-e5900dc7b720"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model scoreboard (sorted by Test ROC AUC):\n",
            "                           model  accuracy  precision   recall  specificity       f1  roc_auc\n",
            "                            FFNN  0.766234   0.687500 0.611111         0.85 0.647059 0.836296\n",
            "   ELM (h=256, act=relu, α=0.01)  0.493506   0.396552 0.851852         0.30 0.541176 0.713519\n",
            "   ELM (h=2000, act=relu, α=0.1)  0.474026   0.378378 0.777778         0.31 0.509091 0.640556\n",
            "ELM (h=500, act=sigmoid, α=0.01)  0.493506   0.388889 0.777778         0.34 0.518519 0.601296\n",
            " ELM (h=1000, act=tanh, α=0.001)  0.506494   0.390000 0.722222         0.39 0.506494 0.595926\n",
            "Saved CSV -> figs/results_ffnn_elm.csv\n"
          ]
        }
      ]
    }
  ]
}