{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMjgQ3ZE2bcdRDXi+VnFiCG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asheta66/Machine-Learning-2024/blob/main/Egypt/Egyptian_Hieroglyph_Classification_via_Lightweight_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "m99LcqcNH_g6",
        "outputId": "fe690f0d-4f86-46fc-e833-bbbe842ddd32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Loading annotations from Google Drive paths...\n",
            "df_train: 2723 | df_val: 778 | df_test: 389\n",
            "Classes (95): ['100', 'Among', 'Angry', 'Ankh', 'Aroura', 'At', 'Bad_Thinking', 'Bandage', 'Bee', 'Belongs']...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │           \u001b[38;5;34m448\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m4,640\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m95\u001b[0m)             │         \u001b[38;5;34m6,175\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">95</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,175</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m29,759\u001b[0m (116.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,759</span> (116.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m29,759\u001b[0m (116.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,759</span> (116.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# Lightweight CNN for Egyptian Hieroglyph Classification\n",
        "# - Loads annotations from Google Drive: train/valid/test/_annotations.csv\n",
        "# - Builds train/val/test tf.data pipelines\n",
        "# - Trains a lightweight CNN\n",
        "# - Reports Accuracy, Precision, Recall, F1 (macro) for train/val/test\n",
        "# - Plots convergence curves (train/val + test per-epoch)\n",
        "# - Plots ROC curves (one-vs-rest) for train/val/test\n",
        "# ------------------------------------------------------------\n",
        "# One-cell, robust to common CSV schemas and image layouts\n",
        "# ============================================================\n",
        "\n",
        "import os, re, glob, sys, math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ------------------ ENV / PATHS ------------------\n",
        "USE_DRIVE = True  # Set to False if running on Kaggle with local dataset\n",
        "BASE_PATH = \"/content/drive/MyDrive/egyptian-hieroglyphs\"  # update if needed\n",
        "\n",
        "if USE_DRIVE:\n",
        "    try:\n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/drive')\n",
        "    except Exception as e:\n",
        "        print(\"Colab drive mount not available; continuing anyway.\", e)\n",
        "\n",
        "# If not using Drive (e.g., Kaggle), set something like:\n",
        "# BASE_PATH = \"/kaggle/input/your-dataset-folder\"\n",
        "\n",
        "# ------------------ CONFIG ------------------\n",
        "IMG_SIZE   = 128\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS     = 15\n",
        "SEED       = 42\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder, label_binarize\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, ConfusionMatrixDisplay,\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    roc_curve, auc\n",
        ")\n",
        "\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# ------------------ HELPERS: LOADING CSVs ------------------\n",
        "def _first_existing(path_list):\n",
        "    for p in path_list:\n",
        "        if os.path.isfile(p):\n",
        "            return p\n",
        "    return None\n",
        "\n",
        "def read_annotations_for_split(base, split):\n",
        "    \"\"\"\n",
        "    Read an annotations CSV for a split (train/valid/test).\n",
        "    Tries several common filenames.\n",
        "    Returns a DataFrame with columns ['image','label'].\n",
        "    \"\"\"\n",
        "    candidates = [\n",
        "        os.path.join(base, split, \"_annotations.csv\"),\n",
        "        os.path.join(base, f\"{split}_annotations.csv\"),\n",
        "        os.path.join(base, split, \"annotations.csv\"),\n",
        "        os.path.join(base, split, \"labels.csv\"),\n",
        "    ]\n",
        "    csv_path = _first_existing(candidates)\n",
        "    if csv_path is None:\n",
        "        raise FileNotFoundError(f\"No annotations CSV found for split '{split}' in {base}. \"\n",
        "                                f\"Tried: {candidates}\")\n",
        "\n",
        "    df_raw = pd.read_csv(csv_path)\n",
        "    # Guess image column\n",
        "    img_cols = [c for c in df_raw.columns if c.lower() in\n",
        "                [\"file\",\"filename\",\"image\",\"image_path\",\"path\",\"img_path\",\"imagefile\"]]\n",
        "    if not img_cols:\n",
        "        for c in df_raw.columns:\n",
        "            if df_raw[c].astype(str).str.contains(r\"\\.(jpg|jpeg|png|bmp|gif)$\", case=False, na=False).any():\n",
        "                img_cols.append(c); break\n",
        "    if not img_cols:\n",
        "        raise ValueError(f\"Could not find image path column in {csv_path}\")\n",
        "    img_col = img_cols[0]\n",
        "\n",
        "    # Guess label column\n",
        "    lbl_cols = [c for c in df_raw.columns if c.lower() in [\"label\",\"class\",\"category\",\"name\"]]\n",
        "    if not lbl_cols:\n",
        "        for c in df_raw.columns:\n",
        "            lc = c.lower()\n",
        "            if \"class\" in lc or \"label\" in lc or \"category\" in lc or lc.endswith(\"name\"):\n",
        "                lbl_cols.append(c); break\n",
        "    if not lbl_cols:\n",
        "        raise ValueError(f\"Could not find label/class column in {csv_path}\")\n",
        "    lbl_col = lbl_cols[0]\n",
        "\n",
        "    df = df_raw[[img_col, lbl_col]].copy()\n",
        "    df.columns = [\"image\",\"label\"]\n",
        "    # If detection-style duplicates, reduce to one label/image (first)\n",
        "    df = df.groupby(\"image\", as_index=False).first()\n",
        "    # Resolve image paths\n",
        "    df[\"image\"] = df[\"image\"].astype(str).apply(lambda p: resolve_img_path(BASE_PATH, split, p))\n",
        "    df = df[df[\"image\"].notnull() & df[\"image\"].apply(os.path.isfile)].copy()\n",
        "    df = df.drop_duplicates(subset=[\"image\"])\n",
        "    return df\n",
        "\n",
        "def resolve_img_path(base, split, p):\n",
        "    \"\"\"\n",
        "    Resolve image path strings to actual files.\n",
        "    Tries:\n",
        "      - absolute paths\n",
        "      - base/split/<p>\n",
        "      - base/split/images/<p>\n",
        "      - base/<p>\n",
        "      - basename lookup anywhere under base\n",
        "    \"\"\"\n",
        "    if os.path.isabs(p) and os.path.isfile(p):\n",
        "        return p\n",
        "    trials = [\n",
        "        os.path.join(base, split, p),\n",
        "        os.path.join(base, split, \"images\", p),\n",
        "        os.path.join(base, p),\n",
        "        os.path.join(base, p.lstrip(\"/\")),\n",
        "    ]\n",
        "    for t in trials:\n",
        "        if os.path.isfile(t):\n",
        "            return t\n",
        "    # basename search\n",
        "    base_name = os.path.basename(p)\n",
        "    hits = glob.glob(os.path.join(base, \"**\", base_name), recursive=True)\n",
        "    for h in hits:\n",
        "        if os.path.isfile(h):\n",
        "            return h\n",
        "    return None\n",
        "\n",
        "# ------------------ HELPERS: TF DATA ------------------\n",
        "def load_image_tf(path, img_size=IMG_SIZE):\n",
        "    img = tf.io.read_file(path)\n",
        "    img = tf.image.decode_image(img, channels=3, expand_animations=False)\n",
        "    img = tf.image.convert_image_dtype(img, tf.float32)  # [0,1]\n",
        "    img = tf.image.resize(img, (img_size, img_size), antialias=True)\n",
        "    return img\n",
        "\n",
        "def make_tf_dataset(paths, labels, batch_size=BATCH_SIZE, shuffle=False, augment=False):\n",
        "    ds_paths = tf.data.Dataset.from_tensor_slices(np.array(paths))\n",
        "    ds_imgs = ds_paths.map(lambda p: load_image_tf(p), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    if augment:\n",
        "        aug = tf.keras.Sequential([\n",
        "            layers.RandomFlip(\"horizontal\"),\n",
        "            layers.RandomRotation(0.05),\n",
        "            layers.RandomZoom(0.1),\n",
        "        ])\n",
        "        ds_imgs = ds_imgs.map(lambda x: aug(x), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    ds_labels = tf.data.Dataset.from_tensor_slices(labels)\n",
        "    ds = tf.data.Dataset.zip((ds_imgs, ds_labels))\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(buffer_size=len(paths), seed=SEED, reshuffle_each_iteration=True)\n",
        "    ds = ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "    return ds\n",
        "\n",
        "# ------------------ MODEL ------------------\n",
        "def build_light_cnn(num_classes):\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(16, (3,3), padding=\"same\", activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
        "        layers.MaxPooling2D(2),\n",
        "\n",
        "        layers.Conv2D(32, (3,3), padding=\"same\", activation='relu'),\n",
        "        layers.MaxPooling2D(2),\n",
        "\n",
        "        layers.Conv2D(64, (3,3), padding=\"same\", activation='relu'),\n",
        "        layers.MaxPooling2D(2),\n",
        "\n",
        "        layers.GlobalAveragePooling2D(),\n",
        "        layers.Dropout(0.25),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# ------------------ CALLBACK: TEST METRICS PER EPOCH ------------------\n",
        "class TestEvalCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, test_ds):\n",
        "        super().__init__()\n",
        "        self.test_ds = test_ds\n",
        "        self.test_loss = []\n",
        "        self.test_acc = []\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        loss, acc = self.model.evaluate(self.test_ds, verbose=0)\n",
        "        self.test_loss.append(loss)\n",
        "        self.test_acc.append(acc)\n",
        "        print(f\" — TEST: loss={loss:.4f} acc={acc:.4f}\")\n",
        "\n",
        "# ------------------ PLOTTING HELPERS ------------------\n",
        "def plot_convergence(history, test_cb):\n",
        "    # Loss\n",
        "    plt.figure(figsize=(6.4,4))\n",
        "    plt.plot(history.history['loss'], label='Train Loss')\n",
        "    if 'val_loss' in history.history:\n",
        "        plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "    if test_cb is not None and test_cb.test_loss:\n",
        "        plt.plot(test_cb.test_loss, label='Test Loss')\n",
        "    plt.title('Convergence (Loss)'); plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.legend(); plt.grid(True)\n",
        "    plt.tight_layout(); plt.show()\n",
        "    # Accuracy\n",
        "    plt.figure(figsize=(6.4,4))\n",
        "    plt.plot(history.history['accuracy'], label='Train Acc')\n",
        "    if 'val_accuracy' in history.history:\n",
        "        plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
        "    if test_cb is not None and test_cb.test_acc:\n",
        "        plt.plot(test_cb.test_acc, label='Test Acc')\n",
        "    plt.title('Convergence (Accuracy)'); plt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.legend(); plt.grid(True)\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "def compute_and_show_metrics(name, y_true, y_prob, class_names, max_classes_in_plot=10):\n",
        "    y_pred = np.argmax(y_prob, axis=1)\n",
        "    acc  = accuracy_score(y_true, y_pred)\n",
        "    prec = precision_score(y_true, y_pred, average='macro', zero_division=0)\n",
        "    rec  = recall_score(y_true, y_pred, average='macro', zero_division=0)\n",
        "    f1   = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
        "    print(f\"\\n=== {name} Metrics ===\")\n",
        "    print(f\"Accuracy : {acc:.4f}\")\n",
        "    print(f\"Precision: {prec:.4f} (macro)\")\n",
        "    print(f\"Recall   : {rec:.4f} (macro)\")\n",
        "    print(f\"F1       : {f1:.4f} (macro)\")\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=range(len(class_names)))\n",
        "    fig, ax = plt.subplots(figsize=(5.8,4.8))\n",
        "    ConfusionMatrixDisplay(cm, display_labels=class_names).plot(ax=ax, colorbar=False, cmap=\"Greens\")\n",
        "    ax.set_title(f\"{name} Confusion Matrix\")\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "    # ROC (one-vs-rest)\n",
        "    y_true_bin = label_binarize(y_true, classes=range(len(class_names)))\n",
        "    # Some splits may miss classes; handle gracefully\n",
        "    fpr, tpr, roc_auc = {}, {}, {}\n",
        "    present = []\n",
        "    for i in range(len(class_names)):\n",
        "        if y_true_bin[:, i].max() == 0:\n",
        "            continue\n",
        "        present.append(i)\n",
        "        fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_prob[:, i])\n",
        "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "    valid_aucs = [roc_auc[i] for i in present]\n",
        "    macro_auc = np.mean(valid_aucs) if valid_aucs else np.nan\n",
        "\n",
        "    # micro-average\n",
        "    if y_true_bin.sum() > 0:\n",
        "        fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_true_bin.ravel(), y_prob.ravel())\n",
        "        roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "\n",
        "    plt.figure(figsize=(6.4,5.2))\n",
        "    # Plot up to max_classes_in_plot class-curves to avoid clutter\n",
        "    to_plot = present[:max_classes_in_plot]\n",
        "    for i in to_plot:\n",
        "        plt.plot(fpr[i], tpr[i], label=f\"{class_names[i]} (AUC={roc_auc[i]:.3f})\")\n",
        "    if len(present) > max_classes_in_plot:\n",
        "        plt.plot([], [], ' ', label=f\"... (+{len(present)-max_classes_in_plot} more classes)\")\n",
        "    if \"micro\" in roc_auc:\n",
        "        plt.plot(fpr[\"micro\"], tpr[\"micro\"], linestyle=\"--\", label=f\"Micro (AUC={roc_auc['micro']:.3f})\")\n",
        "    plt.plot([0,1],[0,1], linestyle=':', label='Chance')\n",
        "    plt.title(f\"{name} ROC (macro AUC={macro_auc:.3f})\")\n",
        "    plt.xlabel(\"False Positive Rate\"); plt.ylabel(\"True Positive Rate\")\n",
        "    plt.legend(fontsize=8, loc=\"lower right\"); plt.grid(True, linestyle=\":\")\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "    return {\"Accuracy\": acc, \"Precision\": prec, \"Recall\": rec, \"F1\": f1, \"MacroAUC\": macro_auc}\n",
        "\n",
        "# ------------------ LOAD DATA ------------------\n",
        "print(\"Loading annotations from Google Drive paths...\")\n",
        "df_train = read_annotations_for_split(BASE_PATH, \"train\")\n",
        "df_val   = read_annotations_for_split(BASE_PATH, \"valid\")  # uses 'valid' split name\n",
        "df_test  = read_annotations_for_split(BASE_PATH, \"test\")\n",
        "\n",
        "print(f\"df_train: {len(df_train)} | df_val: {len(df_val)} | df_test: {len(df_test)}\")\n",
        "\n",
        "# Encode labels jointly (ensures consistent class ids across splits)\n",
        "le = LabelEncoder()\n",
        "all_labels = pd.concat([df_train[\"label\"], df_val[\"label\"], df_test[\"label\"]], axis=0).astype(str).values\n",
        "le.fit(all_labels)\n",
        "class_names = list(le.classes_)\n",
        "num_classes = len(class_names)\n",
        "print(f\"Classes ({num_classes}): {class_names[:10]}{'...' if num_classes>10 else ''}\")\n",
        "\n",
        "df_train[\"y\"] = le.transform(df_train[\"label\"].astype(str))\n",
        "df_val[\"y\"]   = le.transform(df_val[\"label\"].astype(str))\n",
        "df_test[\"y\"]  = le.transform(df_test[\"label\"].astype(str))\n",
        "\n",
        "train_paths, train_labels = df_train[\"image\"].tolist(), df_train[\"y\"].values\n",
        "val_paths,   val_labels   = df_val[\"image\"].tolist(),   df_val[\"y\"].values\n",
        "test_paths,  test_labels  = df_test[\"image\"].tolist(),  df_test[\"y\"].values\n",
        "\n",
        "# ------------------ TF.DATA ------------------\n",
        "train_ds = make_tf_dataset(train_paths, train_labels, shuffle=True,  augment=True)\n",
        "val_ds   = make_tf_dataset(val_paths,   val_labels,   shuffle=False, augment=False)\n",
        "test_ds  = make_tf_dataset(test_paths,  test_labels,  shuffle=False, augment=False)\n",
        "\n",
        "# ------------------ MODEL + TRAIN ------------------\n",
        "model = build_light_cnn(num_classes)\n",
        "model.summary()\n",
        "\n",
        "test_cb = TestEvalCallback(test_ds)\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_ds,\n",
        "    callbacks=[test_cb],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Convergence curves (train/val + test per-epoch)\n",
        "plot_convergence(history, test_cb)\n",
        "\n",
        "# ------------------ FINAL EVALUATIONS ------------------\n",
        "# Collect probabilities\n",
        "train_probs = model.predict(train_ds, verbose=0)\n",
        "val_probs   = model.predict(val_ds,   verbose=0)\n",
        "test_probs  = model.predict(test_ds,  verbose=0)\n",
        "\n",
        "# Collect true labels from the datasets (preserve order)\n",
        "y_train_true = np.concatenate([y.numpy() for _, y in train_ds.unbatch()])\n",
        "y_val_true   = np.concatenate([y.numpy() for _, y in val_ds.unbatch()])\n",
        "y_test_true  = np.concatenate([y.numpy() for _, y in test_ds.unbatch()])\n",
        "\n",
        "# Metrics + Confusion + ROC\n",
        "metrics_train = compute_and_show_metrics(\"Train\", y_train_true, train_probs, class_names)\n",
        "metrics_val   = compute_and_show_metrics(\"Validation\", y_val_true,   val_probs,   class_names)\n",
        "metrics_test  = compute_and_show_metrics(\"Test\",  y_test_true,  test_probs,  class_names)\n",
        "\n",
        "# Summary table\n",
        "summary = pd.DataFrame([\n",
        "    {\"Split\":\"Train\",      **metrics_train},\n",
        "    {\"Split\":\"Validation\", **metrics_val},\n",
        "    {\"Split\":\"Test\",       **metrics_test},\n",
        "]).set_index(\"Split\")\n",
        "print(\"\\n=== Summary (macro metrics) ===\")\n",
        "display(summary)\n"
      ]
    }
  ]
}